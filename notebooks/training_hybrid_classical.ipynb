{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2201ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students/joshua_c/dev/PulmoScanX/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import config\n",
    "from utils.dataset import chest_xray_datasplit, ChestXrayDataset, ChestXrayDatasetWithMask\n",
    "from utils.train import train, validate, compute_pos_weight\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Pretrained CoAtNet-2 with head removed\n",
    "model = timm.create_model(\"coatnet_2_rw_224\", pretrained=True, num_classes=0)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Freeze weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a4036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join(config.DATASET_DIR, 'miccai2023_nih-cxr-lt_labels_test.csv')\n",
    "train_path = os.path.join(config.DATASET_DIR, 'miccai2023_nih-cxr-lt_labels_train.csv')\n",
    "val_path = os.path.join(config.DATASET_DIR, 'miccai2023_nih-cxr-lt_labels_val.csv')\n",
    "\n",
    "# Load all CSVs\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_val = pd.read_csv(val_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# Combine them\n",
    "full_df = pd.concat([df_train, df_val, df_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34c0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Pneumothorax', 'Emphysema', 'Subcutaneous Emphysema', 'Pneumoperitoneum', 'Pneumomediastinum']\n",
    "classes_df = full_df[columns]\n",
    "classes_df = classes_df[classes_df.sum(axis=1) > 0]\n",
    "columns.extend(['id', 'No Finding', 'subj_id'])\n",
    "# Filter full_df based on the index of the filtered classes_df\n",
    "group1_df = full_df.loc[classes_df.index, columns]\n",
    "#group1_df = full_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69cd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "full_dataset = ChestXrayDataset(dataframe=group1_df, img_dir=os.path.join(config.DATASET_DIR, 'cxr', 'images'))\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = chest_xray_datasplit(group1_df, full_dataset, dataset_dir=os.path.join(config.DATASET_DIR, 'cxr', 'images'))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=96, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=96, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=96, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b37082aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_features(model, dataloader):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.view(outputs.size(0), -1).cpu().numpy()  # Flatten features\n",
    "            features.append(outputs)\n",
    "            labels.append(targets.cpu().numpy())\n",
    "\n",
    "    return np.vstack(features), np.vstack(labels)\n",
    "\n",
    "X_train, y_train = extract_features(model, train_loader)\n",
    "X_val, y_val = extract_features(model, val_loader)\n",
    "X_test, y_test = extract_features(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c191c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/students/joshua_c/dev/PulmoScanX/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:22:07] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/data/students/joshua_c/dev/PulmoScanX/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:22:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/data/students/joshua_c/dev/PulmoScanX/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:22:41] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/data/students/joshua_c/dev/PulmoScanX/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:22:57] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/data/students/joshua_c/dev/PulmoScanX/.venv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [00:23:11] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.22607104825275895\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Create base classifier\n",
    "base_model = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Wrap in multi-label classifier\n",
    "clf = MultiOutputClassifier(base_model)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Macro F1:\", f1_score(y_test, y_pred, average='macro'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
